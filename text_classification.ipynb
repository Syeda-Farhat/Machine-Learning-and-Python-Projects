{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1cbbc773",
      "metadata": {
        "id": "1cbbc773"
      },
      "source": [
        "# Text classification using GaussianNB, Random Forest, and Roberta"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a48f997",
      "metadata": {
        "id": "5a48f997"
      },
      "source": [
        "Text Classification: In this project the author implemented different machine learning models for text classsification on the *IMDB Dataset of 50K Movie Reviews*. The dataset is available on kaggle. First of all implemented the text  pre-processing including (missing values, duplicates, tags removal, lower case etc). Then GaussianNB, random forest and roberta with number of differnet techniques to increase the accuracy.\n",
        "\n",
        "Applied transformer model but as we all know that transformer models requires huge memory, even though I reduced the dataset furthermore, but still I was unable to fully executes the model. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3ce9b931",
      "metadata": {
        "id": "3ce9b931"
      },
      "outputs": [],
      "source": [
        "# importing required libraries\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "XYkthrT-ZpBy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYkthrT-ZpBy",
        "outputId": "37477e2b-91a2-4f38-adb9-be809d5ac854"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ThO8RLl9DHGC",
      "metadata": {
        "id": "ThO8RLl9DHGC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "BulbPwSrBGKP",
      "metadata": {
        "id": "BulbPwSrBGKP"
      },
      "outputs": [],
      "source": [
        "data_frame = pd.read_csv('/content/drive/MyDrive/IMDB Dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "936f56e6",
      "metadata": {
        "id": "936f56e6"
      },
      "outputs": [],
      "source": [
        "data_frame = pd.read_csv('C:/Users/Toma Shah/Downloads/txt classification/IMDB Dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9db1830b",
      "metadata": {
        "id": "9db1830b"
      },
      "outputs": [],
      "source": [
        "#due to memory issues instead of using whole data, I have used limited dataset\n",
        "# data_frame = data_frame.iloc[:15000]\n",
        "data_frame = data_frame.iloc[:10000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f794ceb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4f794ceb",
        "outputId": "89eab162-d9d3-4f3b-8c9b-367a8c591b57"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_frame.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c31fb116",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "c31fb116",
        "outputId": "f3b4e3c1-dfa4-423b-b500-3d0f53cb114e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Phil the Alien is one of those quirky films where the humour is based around the oddness of everything rather than actual punchlines.<br /><br />At first it was very odd and pretty funny but as the movie progressed I didn\\'t find the jokes or oddness funny anymore.<br /><br />Its a low budget film (thats never a problem in itself), there were some pretty interesting characters, but eventually I just lost interest.<br /><br />I imagine this film would appeal to a stoner who is currently partaking.<br /><br />For something similar but better try \"Brother from another planet\"'"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_frame['review'][10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "18525cb6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18525cb6",
        "outputId": "0c35843f-3fbb-489a-c9bf-783964ddf569"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "negative    7609\n",
              "positive    7391\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_frame['sentiment'].value_counts() #checking the balance of data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f207966e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f207966e",
        "outputId": "baadffd7-d74d-48a1-c22f-a5ec263ef5b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "review       0\n",
              "sentiment    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_frame.isnull().sum() #checking null values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ea02910b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea02910b",
        "outputId": "3943c2bb-aa23-44e7-b696-b08ef2430f82"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "39"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_frame.duplicated().sum() # checking duplicate values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "2254cc43",
      "metadata": {
        "id": "2254cc43"
      },
      "outputs": [],
      "source": [
        "data_frame = data_frame.drop_duplicates(inplace=False) # dropping the duplicate values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8bbdbf38",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bbdbf38",
        "outputId": "d1b3abb4-c5e8-4fbd-ee34-c0e84bd064f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_frame.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28428090",
      "metadata": {
        "id": "28428090"
      },
      "source": [
        "Basic Preprocessing includes removing tags, coverting whole data into lower case and removing stopwords."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ecb881b9",
      "metadata": {
        "id": "ecb881b9"
      },
      "outputs": [],
      "source": [
        "# removing tags function\n",
        "import re\n",
        "def remove_tags(raw_text):\n",
        "    cleaned_text = re.sub(re.compile('<.*?>'), '', raw_text)\n",
        "    return cleaned_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "670ecc96",
      "metadata": {
        "id": "670ecc96"
      },
      "outputs": [],
      "source": [
        "data_frame['review'] = data_frame['review'].apply(remove_tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b21551de",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "b21551de",
        "outputId": "bd719859-4fc6-492c-a975-380078739bd8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. The filming tec...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14995</th>\n",
              "      <td>Bobcat Goldthwait should be commended for atte...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14996</th>\n",
              "      <td>And it's not because since her days on \"Claris...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14997</th>\n",
              "      <td>A traveling couple (Horton and Hamilton)stumbl...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14998</th>\n",
              "      <td>This film is deeply disappointing. Not only th...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14999</th>\n",
              "      <td>The revelation here is Lana Turner's dancing a...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14961 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review sentiment\n",
              "0      One of the other reviewers has mentioned that ...  positive\n",
              "1      A wonderful little production. The filming tec...  positive\n",
              "2      I thought this was a wonderful way to spend ti...  positive\n",
              "3      Basically there's a family where a little boy ...  negative\n",
              "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
              "...                                                  ...       ...\n",
              "14995  Bobcat Goldthwait should be commended for atte...  negative\n",
              "14996  And it's not because since her days on \"Claris...  positive\n",
              "14997  A traveling couple (Horton and Hamilton)stumbl...  negative\n",
              "14998  This film is deeply disappointing. Not only th...  negative\n",
              "14999  The revelation here is Lana Turner's dancing a...  positive\n",
              "\n",
              "[14961 rows x 2 columns]"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "1e03f81e",
      "metadata": {
        "id": "1e03f81e"
      },
      "outputs": [],
      "source": [
        "# coverting whole data to lower case\n",
        "data_frame['review'] = data_frame['review'].apply(lambda x:x.lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "SXpepkQbbPXA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXpepkQbbPXA",
        "outputId": "9b5a6b14-9866-4a21-e40e-c9bb8e0d7c06"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Download the stopwords resource\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "HdGC8HkqbAlO",
      "metadata": {
        "id": "HdGC8HkqbAlO"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "bdc39311",
      "metadata": {
        "id": "bdc39311"
      },
      "outputs": [],
      "source": [
        "sw_list = stopwords.words('english')\n",
        "\n",
        "data_frame['review'] = data_frame['review'].apply(lambda x: [item for item in x.split() if item not in sw_list]).apply(lambda x:\" \".join(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb3beebd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "eb3beebd",
        "outputId": "ea4e59fc-74bc-4964-d4ab-703cf7172559"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>one reviewers mentioned watching 1 oz episode ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wonderful little production. filming technique...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>thought wonderful way spend time hot summer we...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>basically there's family little boy (jake) thi...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>petter mattei's \"love time money\" visually stu...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14995</th>\n",
              "      <td>bobcat goldthwait commended attempting somethi...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14996</th>\n",
              "      <td>since days \"clarissa explains all\" i've bit cr...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14997</th>\n",
              "      <td>traveling couple (horton hamilton)stumble onto...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14998</th>\n",
              "      <td>film deeply disappointing. wenders displays li...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14999</th>\n",
              "      <td>revelation lana turner's dancing ability. thou...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14961 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review sentiment\n",
              "0      one reviewers mentioned watching 1 oz episode ...  positive\n",
              "1      wonderful little production. filming technique...  positive\n",
              "2      thought wonderful way spend time hot summer we...  positive\n",
              "3      basically there's family little boy (jake) thi...  negative\n",
              "4      petter mattei's \"love time money\" visually stu...  positive\n",
              "...                                                  ...       ...\n",
              "14995  bobcat goldthwait commended attempting somethi...  negative\n",
              "14996  since days \"clarissa explains all\" i've bit cr...  positive\n",
              "14997  traveling couple (horton hamilton)stumble onto...  negative\n",
              "14998  film deeply disappointing. wenders displays li...  negative\n",
              "14999  revelation lana turner's dancing ability. thou...  positive\n",
              "\n",
              "[14961 rows x 2 columns]"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "044b8b36",
      "metadata": {
        "id": "044b8b36"
      },
      "outputs": [],
      "source": [
        "X = data_frame.iloc[:,0:1]\n",
        "y = data_frame['sentiment']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KuXzyrWfb4di",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuXzyrWfb4di",
        "outputId": "cada50b9-bafe-4116-fc0c-41e521c740a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(14961, 1)"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2f50b0d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "c2f50b0d",
        "outputId": "16e0201c-205e-483c-90b1-a9101b21ddfa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>one reviewers mentioned watching 1 oz episode ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wonderful little production. filming technique...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>thought wonderful way spend time hot summer we...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>basically there's family little boy (jake) thi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>petter mattei's \"love time money\" visually stu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14995</th>\n",
              "      <td>bobcat goldthwait commended attempting somethi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14996</th>\n",
              "      <td>since days \"clarissa explains all\" i've bit cr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14997</th>\n",
              "      <td>traveling couple (horton hamilton)stumble onto...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14998</th>\n",
              "      <td>film deeply disappointing. wenders displays li...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14999</th>\n",
              "      <td>revelation lana turner's dancing ability. thou...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14961 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review\n",
              "0      one reviewers mentioned watching 1 oz episode ...\n",
              "1      wonderful little production. filming technique...\n",
              "2      thought wonderful way spend time hot summer we...\n",
              "3      basically there's family little boy (jake) thi...\n",
              "4      petter mattei's \"love time money\" visually stu...\n",
              "...                                                  ...\n",
              "14995  bobcat goldthwait commended attempting somethi...\n",
              "14996  since days \"clarissa explains all\" i've bit cr...\n",
              "14997  traveling couple (horton hamilton)stumble onto...\n",
              "14998  film deeply disappointing. wenders displays li...\n",
              "14999  revelation lana turner's dancing ability. thou...\n",
              "\n",
              "[14961 rows x 1 columns]"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6014ee0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6014ee0",
        "outputId": "be1669a6-888a-426f-e67b-222ad76865a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        positive\n",
              "1        positive\n",
              "2        positive\n",
              "3        negative\n",
              "4        positive\n",
              "           ...   \n",
              "14995    negative\n",
              "14996    positive\n",
              "14997    negative\n",
              "14998    negative\n",
              "14999    positive\n",
              "Name: sentiment, Length: 14961, dtype: object"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "fb01ea97",
      "metadata": {
        "id": "fb01ea97"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "y = encoder.fit_transform(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "e49f7132",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e49f7132",
        "outputId": "391814a4-c3a1-48c3-98c4-b7f3fe6ce118"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 0, 0, 1])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a47c8cf",
      "metadata": {
        "id": "4a47c8cf"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=1) # splitting data for model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59d30e1a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59d30e1a",
        "outputId": "b9d3e82e-5c23-4055-ef1a-78d3c06bda18"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(11968, 1)"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0ced488",
      "metadata": {
        "id": "f0ced488"
      },
      "outputs": [],
      "source": [
        "# Applying BoW\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d038ae3a",
      "metadata": {
        "id": "d038ae3a"
      },
      "outputs": [],
      "source": [
        "cv = CountVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "847ace00",
      "metadata": {
        "id": "847ace00"
      },
      "outputs": [],
      "source": [
        "X_train_bow = cv.fit_transform(X_train['review']).toarray()\n",
        "X_test_bow = cv.transform(X_test['review']).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98e12175",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98e12175",
        "outputId": "f9044e8f-e614-420a-ef64-471d52eb12ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(11968, 57303)"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_bow.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f937899f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "f937899f",
        "outputId": "42530cea-4865-4148-c2cc-1f404a4b70ef"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "GaussianNB()"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# applying GaussiianNB\n",
        "\n",
        "gnb = GaussianNB()\n",
        "\n",
        "gnb.fit(X_train_bow,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7164016f",
      "metadata": {
        "id": "7164016f",
        "outputId": "16ae29aa-086c-45a6-9645-ea879632ef7f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6625459405278984"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = gnb.predict(X_test_bow)\n",
        "\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "accuracy_score(y_test,y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df2da34a",
      "metadata": {
        "id": "df2da34a"
      },
      "source": [
        "Accuracy of GassianNB is too low, but as I have stated earlier that I didnot use the whole dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65a01603",
      "metadata": {
        "id": "65a01603",
        "outputId": "c59f7eb3-a0fd-45bd-f368-c29d4e8ab60b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1144,  359],\n",
              "       [ 651,  839]], dtype=int64)"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "confusion_matrix(y_test,y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8ac4bbf",
      "metadata": {
        "id": "c8ac4bbf"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c3f5b2c",
      "metadata": {
        "id": "8c3f5b2c"
      },
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier() # defning instance of random forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6676b0e0",
      "metadata": {
        "id": "6676b0e0",
        "outputId": "0abc97fd-b732-4da1-baf8-19cd5d2a0301"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8456398262612763"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rf.fit(X_train_bow,y_train)\n",
        "y_pred = rf.predict(X_test_bow)\n",
        "accuracy_score(y_test,y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db90aeaa",
      "metadata": {
        "id": "db90aeaa"
      },
      "source": [
        "Random forest accuracy is increased as compared to gaussianNB, If we applied RF using the whole dataset its accuracy will still be better than GassuianNB."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee64c01b",
      "metadata": {
        "id": "ee64c01b"
      },
      "source": [
        "CountVectorizer is a class from scikit-learn that converts a collection of text documents to a matrix of token counts. It counts the occurrences of each word (token) in the document.\n",
        "\n",
        "max_features=3000 is an optional parameter that limits the number of features (unique words) to the top 3000 most frequent words. This is done to reduce the dimensionality of the feature space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc85e4b2",
      "metadata": {
        "id": "cc85e4b2"
      },
      "outputs": [],
      "source": [
        "cv = CountVectorizer(max_features=3000)\n",
        "\n",
        "X_train_bow = cv.fit_transform(X_train['review']).toarray()\n",
        "X_test_bow = cv.transform(X_test['review']).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f39d5611",
      "metadata": {
        "id": "f39d5611"
      },
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb1d3798",
      "metadata": {
        "id": "fb1d3798",
        "outputId": "f3a59e88-9265-4044-c31c-39bc4de950d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8419645840294019"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rf.fit(X_train_bow,y_train)\n",
        "y_pred = rf.predict(X_test_bow)\n",
        "accuracy_score(y_test,y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3858e4c",
      "metadata": {
        "id": "a3858e4c"
      },
      "source": [
        "ngram_range=(1, 2): This parameter specifies that you want to consider both unigrams (individual words) and bigrams (two consecutive words) when creating the token counts. For example, if you have the sentence \"I love natural language processing,\" the n-grams would include \"I,\" \"love,\" \"natural,\" \"language,\" \"processing,\" \"I love,\" \"love natural,\" \"natural language,\" and so on.\n",
        "\n",
        "max_features=5000: This parameter limits the number of features (unique n-grams) to the top 5000 most frequent ones. This helps control the dimensionality of the feature space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5602297",
      "metadata": {
        "id": "c5602297"
      },
      "outputs": [],
      "source": [
        "cv = CountVectorizer(ngram_range=(1,2),max_features=5000)\n",
        "\n",
        "X_train_bow = cv.fit_transform(X_train['review']).toarray()\n",
        "X_test_bow = cv.transform(X_test['review']).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5142fcdb",
      "metadata": {
        "id": "5142fcdb"
      },
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0930ca1",
      "metadata": {
        "id": "d0930ca1",
        "outputId": "9bea9812-cef1-4c44-d369-66bb9eb8f9cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8416304710992315"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rf.fit(X_train_bow,y_train)\n",
        "y_pred = rf.predict(X_test_bow)\n",
        "accuracy_score(y_test,y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f77c7784",
      "metadata": {
        "id": "f77c7784"
      },
      "source": [
        "## Using TfIdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a4ad25b",
      "metadata": {
        "id": "6a4ad25b"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7efd8b3f",
      "metadata": {
        "id": "7efd8b3f"
      },
      "outputs": [],
      "source": [
        "tfidf = TfidfVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76e2d7ed",
      "metadata": {
        "id": "76e2d7ed"
      },
      "outputs": [],
      "source": [
        "X_train_tfidf = tfidf.fit_transform(X_train['review']).toarray()\n",
        "X_test_tfidf = tfidf.transform(X_test['review'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ead54386",
      "metadata": {
        "id": "ead54386"
      },
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a89c3ed1",
      "metadata": {
        "id": "a89c3ed1",
        "outputId": "3623a2d0-9ea1-48a4-8d8e-efffa1fa3248"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8506515202138323"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rf.fit(X_train_tfidf,y_train)\n",
        "y_pred = rf.predict(X_test_tfidf)\n",
        "\n",
        "accuracy_score(y_test,y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1d3e5ce",
      "metadata": {
        "id": "f1d3e5ce"
      },
      "source": [
        "## Using word2vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a261a8d",
      "metadata": {
        "id": "4a261a8d"
      },
      "outputs": [],
      "source": [
        "import gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4679427f",
      "metadata": {
        "id": "4679427f"
      },
      "outputs": [],
      "source": [
        "from nltk import sent_tokenize\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import Word2Vec,KeyedVectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e0382fa",
      "metadata": {
        "id": "7e0382fa"
      },
      "outputs": [],
      "source": [
        "story = []\n",
        "for doc in data_frame['review']:\n",
        "    raw_sent = sent_tokenize(doc)\n",
        "    for sent in raw_sent:\n",
        "        story.append(simple_preprocess(sent))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26ffbc6e",
      "metadata": {
        "id": "26ffbc6e"
      },
      "outputs": [],
      "source": [
        "model = gensim.models.Word2Vec(\n",
        "    window=10,\n",
        "    min_count=2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d0bdf02",
      "metadata": {
        "id": "2d0bdf02"
      },
      "outputs": [],
      "source": [
        "model.build_vocab(story)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6584707",
      "metadata": {
        "id": "c6584707",
        "outputId": "a0a04695-8cf6-422c-c6ad-f2d9fe3ea20c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(8861242, 9333340)"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.train(story, total_examples=model.corpus_count, epochs=model.epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a21c5aa",
      "metadata": {
        "id": "0a21c5aa",
        "outputId": "5926579c-9d42-401f-c054-2146ca261809"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "38121"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(model.wv.index_to_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1aa25408",
      "metadata": {
        "id": "1aa25408"
      },
      "outputs": [],
      "source": [
        "def document_vector(doc):\n",
        "    # remove out-of-vocabulary words\n",
        "    doc = [word for word in doc.split() if word in model.wv.index_to_key]\n",
        "    return np.mean(model.wv[doc], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4462b4cd",
      "metadata": {
        "id": "4462b4cd",
        "outputId": "e6db6dde-359c-4b30-e05f-fc8553a96fea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-0.1062387 ,  0.57879865, -0.09218969,  0.14872472,  0.07653671,\n",
              "       -0.36878502,  0.21240993,  0.57078224, -0.4596878 , -0.08611797,\n",
              "       -0.13649575, -0.42002127,  0.14361812,  0.43518403,  0.0962563 ,\n",
              "       -0.20527296,  0.19676772, -0.43193722, -0.13806553, -0.63291574,\n",
              "        0.16427596,  0.11688622,  0.01411404, -0.10233656, -0.29268107,\n",
              "       -0.23124242, -0.08162528, -0.09489606, -0.24155933,  0.07943141,\n",
              "        0.40588522, -0.05339793, -0.11622055, -0.18573867, -0.31042463,\n",
              "        0.4238689 , -0.05564627, -0.5161315 , -0.13030896, -0.7088889 ,\n",
              "       -0.00226183, -0.08960303, -0.02157499, -0.15973948,  0.3398637 ,\n",
              "       -0.05734019, -0.25960734, -0.23065479,  0.1594725 ,  0.21978083,\n",
              "        0.08158969, -0.3287221 , -0.20053041, -0.14732364, -0.25804818,\n",
              "        0.417201  ,  0.32288316, -0.04442431, -0.26429772,  0.07237586,\n",
              "       -0.16668832,  0.06561849, -0.21513058,  0.17991115, -0.27956894,\n",
              "        0.1917376 ,  0.11000454,  0.180633  , -0.2990877 ,  0.381256  ,\n",
              "       -0.2711156 ,  0.05752635,  0.35506627, -0.00157812,  0.2932484 ,\n",
              "        0.10483683,  0.10269487, -0.11481974, -0.23218709,  0.20126584,\n",
              "       -0.04641609, -0.07789251, -0.584464  ,  0.4427224 , -0.03114359,\n",
              "       -0.18848382, -0.14675821,  0.32649726,  0.59228796,  0.23410875,\n",
              "        0.5603236 ,  0.22237003, -0.10954715,  0.11905836,  0.47965077,\n",
              "        0.34390998,  0.13869776, -0.26434603,  0.07171181,  0.1804028 ],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "document_vector(data_frame['review'].values[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4090f357",
      "metadata": {
        "id": "4090f357"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3094fdc0",
      "metadata": {
        "id": "3094fdc0",
        "outputId": "da21ed8e-d0eb-452c-aa1d-0d3c003c106c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████████████████████████████████████████████| 14961/14961 [21:58<00:00, 11.34it/s]\n"
          ]
        }
      ],
      "source": [
        "X = []\n",
        "for doc in tqdm(data_frame['review'].values):\n",
        "    X.append(document_vector(doc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cc7d20f",
      "metadata": {
        "id": "1cc7d20f"
      },
      "outputs": [],
      "source": [
        "X = np.array(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdd16d9c",
      "metadata": {
        "id": "cdd16d9c",
        "outputId": "c81c721b-1884-4fc9-cf79-dc4b33215fcd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-0.1062387 ,  0.57879865, -0.09218969,  0.14872472,  0.07653671,\n",
              "       -0.36878502,  0.21240993,  0.57078224, -0.4596878 , -0.08611797,\n",
              "       -0.13649575, -0.42002127,  0.14361812,  0.43518403,  0.0962563 ,\n",
              "       -0.20527296,  0.19676772, -0.43193722, -0.13806553, -0.63291574,\n",
              "        0.16427596,  0.11688622,  0.01411404, -0.10233656, -0.29268107,\n",
              "       -0.23124242, -0.08162528, -0.09489606, -0.24155933,  0.07943141,\n",
              "        0.40588522, -0.05339793, -0.11622055, -0.18573867, -0.31042463,\n",
              "        0.4238689 , -0.05564627, -0.5161315 , -0.13030896, -0.7088889 ,\n",
              "       -0.00226183, -0.08960303, -0.02157499, -0.15973948,  0.3398637 ,\n",
              "       -0.05734019, -0.25960734, -0.23065479,  0.1594725 ,  0.21978083,\n",
              "        0.08158969, -0.3287221 , -0.20053041, -0.14732364, -0.25804818,\n",
              "        0.417201  ,  0.32288316, -0.04442431, -0.26429772,  0.07237586,\n",
              "       -0.16668832,  0.06561849, -0.21513058,  0.17991115, -0.27956894,\n",
              "        0.1917376 ,  0.11000454,  0.180633  , -0.2990877 ,  0.381256  ,\n",
              "       -0.2711156 ,  0.05752635,  0.35506627, -0.00157812,  0.2932484 ,\n",
              "        0.10483683,  0.10269487, -0.11481974, -0.23218709,  0.20126584,\n",
              "       -0.04641609, -0.07789251, -0.584464  ,  0.4427224 , -0.03114359,\n",
              "       -0.18848382, -0.14675821,  0.32649726,  0.59228796,  0.23410875,\n",
              "        0.5603236 ,  0.22237003, -0.10954715,  0.11905836,  0.47965077,\n",
              "        0.34390998,  0.13869776, -0.26434603,  0.07171181,  0.1804028 ],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 128,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b9164c4",
      "metadata": {
        "id": "2b9164c4"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "y = encoder.fit_transform(data_frame['sentiment'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0e18954",
      "metadata": {
        "id": "c0e18954",
        "outputId": "17327335-98ac-42ca-937f-ef4306f880c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 0, 0, 1])"
            ]
          },
          "execution_count": 131,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "deb92892",
      "metadata": {
        "id": "deb92892"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8e04535",
      "metadata": {
        "id": "d8e04535"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58d44672",
      "metadata": {
        "id": "58d44672"
      },
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1274b533",
      "metadata": {
        "id": "1274b533",
        "outputId": "efd8c002-edaa-4c34-e03e-2a1a37d71b55"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7888406281323087"
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rf.fit(X_train,y_train)\n",
        "y_pred = rf.predict(X_test)\n",
        "accuracy_score(y_test,y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83c86ab2",
      "metadata": {
        "id": "83c86ab2"
      },
      "source": [
        "# Applying Transformer model RoBERTa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "e9ea3aeb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9ea3aeb",
        "outputId": "aa30de4d-fdbc-40ad-9545-210760c3ffeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.35.2-py3-none-any.whl (7.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.19.3-py3-none-any.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.19.3 safetensors-0.4.0 tokenizers-0.15.0 transformers-4.35.2\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.14.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.59.2)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch\n",
        "!pip install transformers\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "75ff4f57",
      "metadata": {
        "id": "75ff4f57"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification, AdamW\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "c47bdcfa",
      "metadata": {
        "id": "c47bdcfa"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into training and testing sets\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(data_frame['review'], data_frame['sentiment'], test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "836ed0ad",
      "metadata": {
        "id": "836ed0ad"
      },
      "outputs": [],
      "source": [
        "# Convert labels to numerical format (assuming binary classification)\n",
        "label_mapping = {'positive': 1, 'negative': 0}\n",
        "train_labels = train_labels.map(label_mapping)\n",
        "test_labels = test_labels.map(label_mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "0d2df803",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d2df803",
        "outputId": "c5336d9c-9d0a-4f75-bb03-d6226c93d1dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Labels Info:\n",
            "1    4011\n",
            "0    3975\n",
            "Name: sentiment, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Print some information about the labels\n",
        "print(\"Train Labels Info:\")\n",
        "print(train_labels.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "8bfc5695",
      "metadata": {
        "id": "8bfc5695"
      },
      "outputs": [],
      "source": [
        "# Load RoBERTa tokenizer\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "d76785bd",
      "metadata": {
        "id": "d76785bd"
      },
      "outputs": [],
      "source": [
        "# Tokenize input texts\n",
        "train_encodings = tokenizer(train_texts.tolist(), truncation=True, padding=True, max_length=512, return_tensors='pt')\n",
        "test_encodings = tokenizer(test_texts.tolist(), truncation=True, padding=True, max_length=512, return_tensors='pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "4af53890",
      "metadata": {
        "id": "4af53890"
      },
      "outputs": [],
      "source": [
        "# Create PyTorch tensors for labels\n",
        "train_labels = torch.tensor(train_labels.tolist())\n",
        "test_labels = torch.tensor(test_labels.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "9a5393e3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a5393e3",
        "outputId": "067b9be4-9c0e-412f-bf3d-910af6801b27"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "020d9f4d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "020d9f4d",
        "outputId": "a945348a-dafc-4b62-ba21-dfa70daa517c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(3):  # Adjust the number of epochs as needed\n",
        "    outputs = model(**train_encodings, labels=train_labels)\n",
        "    loss = outputs.loss\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "999b0236",
      "metadata": {
        "id": "999b0236"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    outputs = model(**test_encodings, labels=test_labels)\n",
        "    predictions = torch.argmax(outputs.logits, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91764b8a",
      "metadata": {
        "id": "91764b8a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
